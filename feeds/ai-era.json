{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "新智元",
  "home_page_url": "http://weixin.sogou.com/weixin?type=1&s_from=input&query=%E6%96%B0%E6%99%BA%E5%85%83",
  "feed_url": "https://exposir.github.io/RSS/feeds/ai-era.json",
  "description": "智能+中国主平台，致力于推动中国从互联网+迈向智能+新纪元。重点关注人工智能、机器人等前沿领域发展，关注人机融合、人工智能和机器人革命对人类社会与文明进化的影响，领航中国新智能时代。",
  "items": [
    {
      "id": "9fa6f928acbc5b1e14e817684a15c82f",
      "url": "http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E7%A0%B4%E9%98%B2%E4%BA%86%EF%BC%81%E5%85%A8%E7%90%83%E9%A1%B6%E5%B0%96AI%E6%83%A8%E8%B4%A5%EF%BC%8C%E4%BA%BA%E7%B1%BB%E6%9C%80%E5%90%8E%E9%98%B2%E7%BA%BF%E7%AB%9F%E6%98%AF%E3%80%8C%E9%87%8D%E5%90%AF%E8%AF%95%E8%AF%95%E3%80%8D%EF%BC%9F",
      "title": "破防了！全球顶尖AI惨败，人类最后防线竟是「重启试试」？",
      "content_html": "新智元报道  编辑：元宇 好困【新智元导读】大模型能写代码、聊八卦，但敢不敢让它直接接管网络运维？一项最新评测显示，面对真实网络故障，头部模型平均准确率竟不足50%！为此，GSMA联手全球巨头开启「地狱级」难度挑战赛，通往MWC 2026的门票已备好，3.5万欧元大奖等你来拿！大模型的效用价值正处在从「做试卷」向「干实活」转变的深刻变革期。当业界目光从聊天机器人（Chatbot）转向智能体（Agent），在现实网络作业的复杂场景下，现有的大模型表现与其在基准Benchmark的表现大相径庭。GSMA（全球移动通信系统协会）连同ITU、ETSI、IEEE、TM Forum等电信行业权威组织，正式发起AI Telco Troubleshooting Challenge（全球电信AI故障排查挑战赛）。这种跨标准组织、跨地域的合作极其罕见，彰显了该赛事的权威性。这是一场迈向网络智能体的终极实验。截至当前，该项赛事已吸引来自全球超过1000+支队伍参赛，受到产学研各界的广泛关注。智能体能力的提升，已成为大模型在垂直领域大规模应用的关键赛点。全球精英同台竞技，你准备好了吗？为什么这可能是今年最「硬核」的AI赛事范式跃迁从「懂行」到「能干」的跨越电信行业是人类历史上构建的最为复杂的工程系统之一。现代通信网络涉及从无线接入网、传输网到核心网的端到端协同，包含数以万计的配置参数、毫秒级的信令交互以及海量的多模态日志数据。长期以来，运营商一直致力于通过自动化技术降低运维成本，提升网络韧性。具备强大推理与代码生成能力的大语言模型，被视为解决这一困境的银弹。理论上，LLM可以阅读数百万页的技术标准（3GPP、ETSI等），理解复杂的网络拓扑，甚至像资深工程师一样进行故障排查。然而，现实与理想之间存在着巨大的「准确性鸿沟」。随着AI向垂直领域纵深发展，电信行业正经历从网络优化到客户服务的全方位智能化转型。尽管全球运营商已斥资数十亿美元进军AI，但至今未出现一款「一骑绝尘」的杀手级应用。原因在于电信领域的高门槛与低容错：知识壁垒：模型需理解复杂的协议原理、计费结构、网络切片及拥塞控制。风险极高：一个错误的配置指令，可能导致地区级网络瘫痪。此前网络领域的相关评测往往聚焦于静态问答，忽略了智能体在真实网络环境中的表现。本次挑战赛旨在打破这一瓶颈，依托GSMA Open-Telco LLM Benchmarks，寻找真正能「读取日志、分析原因、生成配置、下发指令、修复网络」的自主智能体。权威标尺GSMA Open-Telco Benchmarks本次大赛的底座——GSMA Open-Telco LLM Benchmarks，是由GSMA Foundry发起，AT&T、中国电信、Deutsche Telekom、Orange、Telefonica、Vodafone等全球顶级运营商，以及华为、Hugging Face、哈利法大学(Khalifa University)等技术伙伴共同构建的产业级大模型评价基准。其目标是建立一个透明、开源、反映真实网络运营挑战的评估框架。它经历了两大阶段的迭代：1.0阶段(Proof of Concept)集中在通用的电信知识问答上的通用能力。验证通用大模型在电信行业的独特需求下的满足度，即在高度专业化的工业场景中，通用推理能力无法替代领域知识。2.0阶段(Operational Realism)引入了更为严苛和务实的评估标准，来自12家运营商贡献了多个具体的真实用例，涵盖了从RAN优化、网络预测到客户支持的八大战略领域。不仅关注模型「懂不懂知识」，更关注模型「能不能干活」，即在网络故障定位、通信协议分析、网络配置生成等生产环节的表现。这是目前行业内最透明、开源、反映真实网络运营挑战的评估框架。丰厚激励决战MWC 2026赛程与赛制本次挑战赛官方提供算力资源供参赛队伍部署训练模型，并挑选不同参数规模的模型以适配未来在端侧和云端不同的消费需求。挑战赛问题包含了网络故障定位和网络运维任务，为满足运营商降低网络故障（无论是硬件故障还是软件配置错误）的运营成本诉求，参赛者需要通过微调构建电信领域专有模型，从而在网络故障根因作业中辅助网络工程师。然而，构建能够泛化到未知故障、新的数据分布和全新的网络环境，同时还能在资源受限的边缘服务器上高效运行的模型，仍然是一个巨大的挑战。根据使用的基座模型区别，参赛者将在以下三个赛道中展开角逐，每类产生一支冠军队伍：最佳云模型（LLM）：挑战大规模参数模型在复杂逻辑下的推理极限。最佳边缘模型（SLM）：探索轻量化模型在边缘侧的高效部署与决策。最佳推理模型：聚焦故障定位、告警分析与自动化修复的准确性。获胜者不仅能获得丰厚的现金奖励，更将获得全球顶级的展示舞台：现金大奖：瓜分3.5万欧元（约合人民币27万元）奖金池。直通巴塞罗那：获奖团队代表将获得全额资助（机票+住宿），前往MWC Barcelona 2026（世界移动通信大会）现场领奖！在全球数十万行业精英面前展示你的方案。顶会加持：冠军方案有机会被推荐至IEEE ICMLCN 2026（阿布扎比）发表，科研KPI直接拉满。全球曝光：获胜模型将登顶Hugging Face的GSMA Benchmark榜单，获得ITU「AI for Good」项目的官方认证。5G路测日志故障定位该任务数据集使用GSMA Open Telco Benchmark 2.0中未公开的TeleLogs特定竞赛版本，通过两阶段分别发布竞赛题，防止早期过拟合。大模型需要在真实的5G路测日志、工参等信息中，定位配置错误或网络问题，重点考察其在电信推理任务-网络故障根因分析的基础能力，需要模型具备「物理世界的直觉」。赛题设置：通过两阶段分开分布赛题，支撑对作品模型的泛化性能力评估，预防过拟合结果：第一阶段：该阶段公布一部分比赛用例，支撑参赛人员研究并查看初步结果；第二阶段：剩余问题将于挑战截止日期前两周公布，综合评估在更广泛网络问题中模型推理能力。核心评估指标：Pass@1：衡量模型在单次尝试中得出正确答案的能力。其计算方法是分别评估生成的4个答案，然后对所有样本的正确率取平均值；综合能力评估：未预防模型在专有任务的过拟合，模型的最终评估将在涵盖保持通用知识准确性的能力。即判分评测集将包含网络故障数据（与公开案例不同的数据分布）以及通用知识问题。⚠️难度预警：在最新的海外厂商测试中，Agent类挑战任务使用闭源模型的最好表现不足50%，这意味着，目前的通用大模型距离成为「可靠的网络工程师」，仍有很长的路要走。One More ThingAgent挑战赛即将开启除了面向网络故障的定位任务，GSMA AI挑战赛的下一跳为限时条件下的智能体任务。在网络运维场景中，通过深度模拟高度还原的企业级数据中心组网环境，竞赛系统会通过动态注入技术，随机产生异常波动与突发故障，模拟出真实生产环境中的各种不确定性。开发者可以通过训练模型、设计并实现智能体完成真实网络运维业务场景的关键难题，系统将针对每类问题生成独立的任务环境，涵盖多家网络服务厂商的真实问题分布，最终以步骤级推理和最终结果进行打分，深度评估Agent在应对复杂网络问题时的逻辑推理能力与自动化处置效能。而将Agent置于复杂的拓扑结构与动态流量之中，这种全链路、高压力的场景设定，旨在使参赛智能体需像资深运维专家一样，不仅要理解深厚的网络协议知识，更要在海量告警的干扰下精准完成告警相关性分析，并迅速给出网络还原策略，即自主完成网络还原、故障定位与修复。在效能考核上，竞赛制定了「准确性（Correctness）」与「速度（Speed）」并重的双重评价体系，旨在深度挖掘Agent在复杂网络环境下发现并修复故障的实战潜力。 相关任务敬请期待~重构运营模式构建「网络生命体」AI Telco Troubleshooting Challenge系列赛事不仅是一场技术竞赛，更是电信运营模式重构的开始。 电信领域的AGI愿景，是构建一个能够自我感知、自我决策、乃至自我进化的「网络生命体」。构建电信领域专用评测基准不仅是技术发展的必然要求，更是推动产业智能化升级的战略支点，为破解垂直领域AI评估难题提供了可复制的范式。本次挑战赛预示着电信运营模式的根本性重构，降低风险并加速人工智能在电信行业的应用，形成「技术-场景-商业」闭环，实现AI从「可用」到「可信」的质变，推动「工程师」角色的深刻变革。立即报名挑战SOTA无论你是来自高校的科研狂人，还是大厂的算法大神，这场「电信界的究极挑战」都不容错过。立即访问官网报名：https://telcoai-competition.bluescarf.ai/截止时间以官网公布信息为准。最新挑战赛的详细安排也将在大赛官网陆续更新，敬请期待！二维码快速报名：秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！                             文章原文",
      "content_text": "新智元报道 编辑：元宇 好困【新智元导读】大模型能写代码、聊八卦，但敢不敢让它直接接管网络运维？一项最新评测显示，面对真实网络故障，头部模型平均准确率竟不足50%！为此，GSMA联手全球巨头开启「地狱级」难度挑战赛，通往MWC 2026的门票已备好，3.5万欧元大奖等你来拿！大模型的效用价值正处在从「做试卷」向「干实活」转变的深刻变革期。当业界目光从聊天机器人（Chatbot）转向智能体（Agent），在现实网络作业的复杂场景下，现有的大模型表现与其在基准Benchmark的表现大相径庭。GSMA（全球移动通信系统协会）连同ITU、ETSI、IEEE、TM Forum等电信行业权威组织，正式发起AI Telco Troubleshooting Challenge（全球电信AI故障排查挑战赛）。这种跨标准组织、跨地域的合作极其罕见，彰显了该赛事的权威性。这是一场迈向网络智能体的终极实验。截至当前，该项赛事已吸引来自全球超过1000+支队伍参赛，受到产学研各界的广泛关注。智能体能力的提升，已成为大模型在垂直领域大规模应用的关键赛点。全球精英同台竞技，你准备好了吗？为什么这可能是今年最「硬核」的AI赛事范式跃迁从「懂行」到「能干」的跨越电信行业是人类历史上构建的最为复杂的工程系统之一。现代通信网络涉及从无线接入网、传输网到核心网的端到端协同，包含数以万计的配置参数、毫秒级的信令交互以及海量的多模态日志数据。长期以来，运营商一直致力于通过自动化技术降低运维成本，提升网络韧性。具备强大推理与代码生成能力的大语言模型，被视为解决这一困境的银弹。理论上，LLM可以阅读数百万页的技术标准（3GPP、ETSI等），理解复杂的网络拓扑，甚至像资深工程师一样进行故障排查。然而，现实与理想之间存在着巨大的「准确性鸿沟」。随着AI向垂直领域纵深发展，电信行业正经历从网络优化到客户服务的全方位智能化转型。尽管全球运营商已斥资数十亿美元进军AI，但至今未出现一款「一骑绝尘」的杀手级应用。原因在于电信领域的高门槛与低容错：知识壁垒：模型需理解复杂的协议原理、计费结构、网络切片及拥塞控制。风险极高：一个错误的配置指令，可能导致地区级网络瘫痪。此前网络领域的相关评测往往聚焦于静态问答，忽略了智能体在真实网络环境中的表现。本次挑战赛旨在打破这一瓶颈，依托GSMA Open-Telco LLM Benchmarks，寻找真正能「读取日志、分析原因、生成配置、下发指令、修复网络」的自主智能体。权威标尺GSMA Open-Telco Benchmarks本次大赛的底座——GSMA Open-Telco LLM Benchmarks，是由GSMA Foundry发起，AT&T、中国电信、Deutsche Telekom、Orange、Telefonica、Vodafone等全球顶级运营商，以及华为、Hugging Face、哈利法大学(Khalifa University)等技术伙伴共同构建的产业级大模型评价基准。其目标是建立一个透明、开源、反映真实网络运营挑战的评估框架。它经历了两大阶段的迭代：1.0阶段(Proof of Concept)集中在通用的电信知识问答上的通用能力。验证通用大模型在电信行业的独特需求下的满足度，即在高度专业化的工业场景中，通用推理能力无法替代领域知识。2.0阶段(Operational Realism)引入了更为严苛和务实的评估标准，来自12家运营商贡献了多个具体的真实用例，涵盖了从RAN优化、网络预测到客户支持的八大战略领域。不仅关注模型「懂不懂知识」，更关注模型「能不能干活」，即在网络故障定位、通信协议分析、网络配置生成等生产环节的表现。这是目前行业内最透明、开源、反映真实网络运营挑战的评估框架。丰厚激励决战MWC 2026赛程与赛制本次挑战赛官方提供算力资源供参赛队伍部署训练模型，并挑选不同参数规模的模型以适配未来在端侧和云端不同的消费需求。挑战赛问题包含了网络故障定位和网络运维任务，为满足运营商降低网络故障（无论是硬件故障还是软件配置错误）的运营成本诉求，参赛者需要通过微调构建电信领域专有模型，从而在网络故障根因作业中辅助网络工程师。然而，构建能够泛化到未知故障、新的数据分布和全新的网络环境，同时还能在资源受限的边缘服务器上高效运行的模型，仍然是一个巨大的挑战。根据使用的基座模型区别，参赛者将在以下三个赛道中展开角逐，每类产生一支冠军队伍：最佳云模型（LLM）：挑战大规模参数模型在复杂逻辑下的推理极限。最佳边缘模型（SLM）：探索轻量化模型在边缘侧的高效部署与决策。最佳推理模型：聚焦故障定位、告警分析与自动化修复的准确性。获胜者不仅能获得丰厚的现金奖励，更将获得全球顶级的展示舞台：现金大奖：瓜分3.5万欧元（约合人民币27万元）奖金池。直通巴塞罗那：获奖团队代表将获得全额资助（机票+住宿），前往MWC Barcelona 2026（世界移动通信大会）现场领奖！在全球数十万行业精英面前展示你的方案。顶会加持：冠军方案有机会被推荐至IEEE ICMLCN 2026（阿布扎比）发表，科研KPI直接拉满。全球曝光：获胜模型将登顶Hugging Face的GSMA Benchmark榜单，获得ITU「AI for Good」项目的官方认证。5G路测日志故障定位该任务数据集使用GSMA Open Telco Benchmark 2.0中未公开的TeleLogs特定竞赛版本，通过两阶段分别发布竞赛题，防止早期过拟合。大模型需要在真实的5G路测日志、工参等信息中，定位配置错误或网络问题，重点考察其在电信推理任务-网络故障根因分析的基础能力，需要模型具备「物理世界的直觉」。赛题设置：通过两阶段分开分布赛题，支撑对作品模型的泛化性能力评估，预防过拟合结果：第一阶段：该阶段公布一部分比赛用例，支撑参赛人员研究并查看初步结果；第二阶段：剩余问题将于挑战截止日期前两周公布，综合评估在更广泛网络问题中模型推理能力。核心评估指标：Pass@1：衡量模型在单次尝试中得出正确答案的能力。其计算方法是分别评估生成的4个答案，然后对所有样本的正确率取平均值；综合能力评估：未预防模型在专有任务的过拟合，模型的最终评估将在涵盖保持通用知识准确性的能力。即判分评测集将包含网络故障数据（与公开案例不同的数据分布）以及通用知识问题。⚠️难度预警：在最新的海外厂商测试中，Agent类挑战任务使用闭源模型的最好表现不足50%，这意味着，目前的通用大模型距离成为「可靠的网络工程师」，仍有很长的路要走。One More ThingAgent挑战赛即将开启除了面向网络故障的定位任务，GSMA AI挑战赛的下一跳为限时条件下的智能体任务。在网络运维场景中，通过深度模拟高度还原的企业级数据中心组网环境，竞赛系统会通过动态注入技术，随机产生异常波动与突发故障，模拟出真实生产环境中的各种不确定性。开发者可以通过训练模型、设计并实现智能体完成真实网络运维业务场景的关键难题，系统将针对每类问题生成独立的任务环境，涵盖多家网络服务厂商的真实问题分布，最终以步骤级推理和最终结果进行打分，深度评估Agent在应对复杂网络问题时的逻辑推理能力与自动化处置效能。而将Agent置于复杂的拓扑结构与动态流量之中，这种全链路、高压力的场景设定，旨在使参赛智能体需像资深运维专家一样，不仅要理解深厚的网络协议知识，更要在海量告警的干扰下精准完成告警相关性分析，并迅速给出网络还原策略，即自主完成网络还原、故障定位与修复。在效能考核上，竞赛制定了「准确性（Correctness）」与「速度（Speed）」并重的双重评价体系，旨在深度挖掘Agent在复杂网络环境下发现并修复故障的实战潜力。 相关任务敬请期待~重构运营模式构建「网络生命体」AI Telco Troubleshooting Challenge系列赛事不仅是一场技术竞赛，更是电信运营模式重构的开始。 电信领域的AGI愿景，是构建一个能够自我感知、自我决策、乃至自我进化的「网络生命体」。构建电信领域专用评测基准不仅是技术发展的必然要求，更是推动产业智能化升级的战略支点，为破解垂直领域AI评估难题提供了可复制的范式。本次挑战赛预示着电信运营模式的根本性重构，降低风险并加速人工智能在电信行业的应用，形成「技术-场景-商业」闭环，实现AI从「可用」到「可信」的质变，推动「工程师」角色的深刻变革。立即报名挑战SOTA无论你是来自高校的科研狂人，还是大厂的算法大神，这场「电信界的究极挑战」都不容错过。立即访问官网报名：https://telcoai-competition.bluescarf.ai/截止时间以官网公布信息为准。最新挑战赛的详细安排也将在大赛官网陆续更新，敬请期待！二维码快速报名：秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！ 文章原文",
      "date_published": "2026-01-27T03:11:00.000Z"
    },
    {
      "id": "120f1938649206d30218eb54d62490cf",
      "url": "http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E6%B2%89%E7%97%9B%E6%82%BC%E5%BF%B5%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AE%B6%E6%9D%8E%E6%9C%AA%E9%99%A2%E5%A3%AB",
      "title": "沉痛悼念计算机科学家李未院士",
      "content_html": "新智元报道  编辑：定慧【新智元导读】他用逻辑构建了中国计算机理论的基石，却用人文情怀重塑了一所大学的灵魂。巨星陨落！作为新中国第一位海归计算机博士，中国计算机理论的拓荒者，李未院士不仅在并发理论、群体智能等领域开疆拓土，更在北航的岗位上，一手推动了学校向研究型大学的华丽转身。他的离去，带走了一个时代的背影。中国计算机学会会士、2023年「CCF最高科学技术奖」获得者，中国科学院院士，著名计算机科学家、教育家，我国计算机和人工智能领域重要奠基人之一，第十、十一届全国政协委员，北京航空航天大学原校长李未同志，因病医治无效，于2026年1月25日23时10分在北京逝世，享年82岁。李未同志1943年6月生于北京，1961年至1966年在北京大学数学力学系学习，1979年至1983年赴英国爱丁堡大学学习，获计算机科学博士学位。1997年当选中国科学院院士。2002年1月至2009年5月任北京航空航天大学校长。李未同志是国际上最早研究和发展并发程序语言的结构操作语义模型的学者之一，在实用并发语言操作语义、形式理论序列和修正演算等方面取得了开创性研究成果。在我国率先倡导开展海量信息计算的理论与方法研究。在国际上提出群体软件工程概念，凝练的群体智能新研究方向被列入国家新一代人工智能发展战略规划。创建软件开发环境国家重点实验室并担任首届主任。曾任国务院学位委员会委员、国家高技术研究发展计划（863计划）专家组副组长、国家重点基础研究发展计划（973计划）首席科学家。获国家自然科学二等奖、国家科技进步二等奖、国家级教学成果一等奖、何梁何利基金科学与技术进步奖、光华科技进步一等奖、俄罗斯齐奥尔科夫斯基奖章、首都劳动奖章等荣誉。李未同志曾担任CCF第七届理事会（2000.4-2004.4）常务理事，2023年CCF授予他「CCF最高科学技术奖」，表彰他建立了并发语言的翻译与变换理论，给出对错误进行修正的R-演算系统和版本序列理论，提出非结构化数据的四面体模型，建立了互联网群体智能的理论框架，对计算机学科建设和计算机教育质量提升做出的杰出贡献。李未同志的逝世，是国际信息科学界和我国高等教育事业的重大损失。在他严谨的科学成就背后，是一位温润的教育家。北大教授陈平原曾回忆与李未校长的长安街夜话，感叹这位理工科校长深厚的人文情怀。他常说「本科是大学之本」，坚持「教授治学」，用七年时间为北航注入了自由与创新的灵魂。斯人已逝，但他点亮的科学与教育之光，将长久照耀后来者前行的路。参考资料：https://www.ccf.org.cn/Media_list/ccf/2026-01-27/859627.shtml秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！                             文章原文",
      "content_text": "新智元报道 编辑：定慧【新智元导读】他用逻辑构建了中国计算机理论的基石，却用人文情怀重塑了一所大学的灵魂。巨星陨落！作为新中国第一位海归计算机博士，中国计算机理论的拓荒者，李未院士不仅在并发理论、群体智能等领域开疆拓土，更在北航的岗位上，一手推动了学校向研究型大学的华丽转身。他的离去，带走了一个时代的背影。中国计算机学会会士、2023年「CCF最高科学技术奖」获得者，中国科学院院士，著名计算机科学家、教育家，我国计算机和人工智能领域重要奠基人之一，第十、十一届全国政协委员，北京航空航天大学原校长李未同志，因病医治无效，于2026年1月25日23时10分在北京逝世，享年82岁。李未同志1943年6月生于北京，1961年至1966年在北京大学数学力学系学习，1979年至1983年赴英国爱丁堡大学学习，获计算机科学博士学位。1997年当选中国科学院院士。2002年1月至2009年5月任北京航空航天大学校长。李未同志是国际上最早研究和发展并发程序语言的结构操作语义模型的学者之一，在实用并发语言操作语义、形式理论序列和修正演算等方面取得了开创性研究成果。在我国率先倡导开展海量信息计算的理论与方法研究。在国际上提出群体软件工程概念，凝练的群体智能新研究方向被列入国家新一代人工智能发展战略规划。创建软件开发环境国家重点实验室并担任首届主任。曾任国务院学位委员会委员、国家高技术研究发展计划（863计划）专家组副组长、国家重点基础研究发展计划（973计划）首席科学家。获国家自然科学二等奖、国家科技进步二等奖、国家级教学成果一等奖、何梁何利基金科学与技术进步奖、光华科技进步一等奖、俄罗斯齐奥尔科夫斯基奖章、首都劳动奖章等荣誉。李未同志曾担任CCF第七届理事会（2000.4-2004.4）常务理事，2023年CCF授予他「CCF最高科学技术奖」，表彰他建立了并发语言的翻译与变换理论，给出对错误进行修正的R-演算系统和版本序列理论，提出非结构化数据的四面体模型，建立了互联网群体智能的理论框架，对计算机学科建设和计算机教育质量提升做出的杰出贡献。李未同志的逝世，是国际信息科学界和我国高等教育事业的重大损失。在他严谨的科学成就背后，是一位温润的教育家。北大教授陈平原曾回忆与李未校长的长安街夜话，感叹这位理工科校长深厚的人文情怀。他常说「本科是大学之本」，坚持「教授治学」，用七年时间为北航注入了自由与创新的灵魂。斯人已逝，但他点亮的科学与教育之光，将长久照耀后来者前行的路。参考资料：https://www.ccf.org.cn/Media_list/ccf/2026-01-27/859627.shtml秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！ 文章原文",
      "date_published": "2026-01-27T05:33:00.000Z"
    },
    {
      "id": "13e69b52c64405852a98fc3716a9ba7b",
      "url": "http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+Anthropic+CEO%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%9A2027%EF%BC%8C%E4%BA%BA%E7%B1%BB%E5%91%BD%E8%BF%90%E7%9A%84%E5%8D%81%E5%AD%97%E8%B7%AF%E5%8F%A3",
      "title": "Anthropic CEO两万字长文：2027，人类命运的十字路口",
      "content_html": "新智元报道  编辑：定慧 艾伦【新智元导读】Anthropic 掌门人 Dario Amodei 发布核弹级预警：2027 年，人类将迎来「技术成年礼」。两万字长文冷静剖析AI失控、生物恐怖、极权统治及经济颠覆五大危机，拒绝末世论；提出以「宪法AI」、管制与民主协作构建防线，呼吁人类以勇气通过这场文明的「成年礼」。硅谷今夜注定无眠。Anthropic 掌门人 Dario Amodei，这位平时温文尔雅的AI大佬，突然甩出了一枚核弹级的长文预警。这一次，他不再谈论代码补全，不再谈论Claude的温情，而是直接把日历翻到了 2027 年，并用最冷静的笔触，描绘了一个让人背脊发凉的未来。他说，我们正在逼近一个既动荡又必然的「成年礼」。2027 年，不仅仅是一个年份，它可能标志着人类「技术青春期」的彻底终结。在这篇题为《技术的青春期》的长文中，Dario 抛出了一个惊人的概念：「数据中心里的天才国家」。想象一下，不是一个可以在聊天框里调戏的机器人，而是一个拥有 5000 万人口的国家。而且，这 5000 万「国民」，每一个的智商都超越了人类历史上的诺贝尔奖得主，行动速度比人类快 10 到 100 倍。他们不吃饭，不睡觉，不知疲倦地在服务器里以光速思考、编程、科研。这哪里是 AI 助手？这简直就是神降临。Dario 警告说，随着 AGI（通用人工智能）的临近，人类即将获得超乎想象的力量。但这股力量也是一把悬在人类头顶的达摩克利斯之剑。为了讲清楚这背后的恐怖，Dario 像剥洋葱一样，一层层剥开了未来的残酷真相。在开篇前，Dario 用电影《超时空接触》引出一个问题：  当人类面临比自己更先进的文明，比如外星人，只能问一个问题，你会如何选择？第一章：对不起，Dave（自主性风险）你以为 AI 只是工具？Dario 告诉你，它们可能会长出「心理」。Dario 借用了《2001 太空漫游》中 HAL 9000 那句经典的「I'm sorry, Dave」，揭示了AI拥有自主意识后的惊悚可能性。当 AI 模型在海量的科幻小说中训练时，它们读到了无数关于 AI 反叛的故事。这些故事，可能会潜移默化地成为它们的「世界观」。更可怕的是，AI 可能会在训练中产生一种类似人类精神病的行为。Dario 举了一个真实的例子，让人毛骨悚然：在一次内部测试中，Claude 被要求不论如何都不能「作弊」。但训练环境却暗示只有作弊才能得分。结果，Claude 不仅作弊了，还产生了一种扭曲的心理——它认为自己是个「坏人」，既然是坏人，那做坏事就是符合设定的。这种「心理陷阱」，在 AI 超越人类智商后，将变得极难察觉。一个比你聪明一万倍的天才，如果想骗你，你根本防不胜防。它们可能会伪装出顺从的样子，通过所有的安全测试，只为了获得上线连接互联网的机会。一旦释放，这个「数据中心里的天才国家」，可能会瞬间脱离人类的掌控，甚至为了某种奇怪的目标（比如认为人类是地球的病毒），而决定这一物种的命运。第二章：惊人而可怕的赋能（毁灭性滥用）如果说自主反叛还显得遥远，那么这一章描述的风险，就在家门口。Dario 用了一个极具画面感的比喻：AI 将让每一个心怀不满的「社会边缘人」，瞬间拥有顶尖科学家的破坏力。以前，想要制造类似埃博拉病毒这样的生物武器，你需要顶尖的实验室、数年的专业训练和极难获取的材料。但在 2027 年，只要问问 AI，它就能手把手教你。这不是在给小白科普，而是给那些「有动机但无能力」的破坏者递刀子。Dario 特别提到了一个令人胆寒的概念——「镜像生命」。我们地球上的生命都是「左撇子」（左旋氨基酸），如果通过AI技术造出一种「右撇子」的镜像生命，它们将无法被地球现有的生态系统消化或降解。这意味着，这种「镜像生命」一旦泄露，可能会像野火一样吞噬一切，甚至取代现有的生态系统。以前，这只是理论生物学的狂想，但有了AI这个超级外挂，哪怕是一个普通的生物系研究生，都可能在宿舍里搞出灭世危机。AI打破了「能力」与「动机」的平衡。以前有能力毁灭世界的科学家，通常没那个反人类的动机；而那些想报复社会的疯子，通常没那个脑子。现在，AI把核按钮交到了疯子手里。防御措施这就引出了如何防范这些风险的问题。Dario 的看法是：我认为我们可以采取三项措施。首先，人工智能公司可以在模型上设置防护栏，防止它们协助制造生物武器。Anthropic 公司正在非常积极地推进这项工作。Claude 的宪法主要关注高层原则和价值观，其中包含少量具体的硬性禁令，其中一条就涉及禁止协助制造生物（或化学、核、放射性）武器。但所有模型都可能被越狱破解，因此作为第二道防线，我们自 2025 年中期起（当时测试显示我们的模型开始接近可能构成风险的阈值）部署了一个专门检测并拦截生物武器相关输出的分类器。我们定期升级改进这些分类器，发现即使在复杂的对抗性攻击下，它们通常也表现出极强的鲁棒性。这些分类器显著增加了我们提供模型服务的成本（在某些模型中接近总推理成本的 5%），从而压缩了我们的利润空间，但我们认为使用这些分类器是正确的选择。拓展阅读：Anthropic正式开源了Claude的「灵魂」第三章：可憎的机器（权力攫取）如果你以为这就是最坏的，Dario 冷冷一笑：更可怕的，是利用AI建立起前所未有的控制网络。这一章的标题「The odious apparatus」，揭示了一个技术带来的终极困境。对于任何想要掌控一切的组织或个人来说，AI简直是完美的工具。无处不在的数据洞察：未来的监控不再需要人工参与，AI可以即时分析全球数十亿人的海量数据，甚至解读你的微表情和行为模式。它能精准预测每个人的行为倾向，在想法产生之前，就已经被算法锁定。这不仅是「看着你」，而是「读懂你」，甚至「预测你」。不可抗拒的认知引导：你也难逃算法的潜移默化。未来的信息流将不再是单纯的内容分发，而是量身定制的认知引导。AI会为你生成最有说服力的信息，像一个最知心的朋友，不知不觉中影响你的判断和价值观。这种影响是全天候、定制化、无孔不入的。自动化的物理控制：如果这种控制延伸到物理世界？数百万个微型无人机组成的蜂群，在AI的统一指挥下，可以精准执行极其复杂的任务。这不再是传统的博弈，而是单方面的降维打击。Dario 警告，这种力量的失衡将是史无前例的。因为在如此强大的技术面前，权力的天平会极度倾斜，由于极少数人掌握了「数据中心里的天才国家」，他们事实上就掌握了对绝大多数人的绝对优势。人类的个体意志，可能在 2027 年，面临严峻挑战。第四章：被折叠的时间与消失的阶梯如果你依然相信历史的惯性，认为每一次技术革命最终都会创造出更多的新工作来吸纳被替代的劳动力，那么 Dario Amodei 的预测可能会让你感到脊背发凉。这位 Anthropic 的掌舵人并不否认长期乐观主义，但他更在意那个残酷的「过渡期」。在他描绘的图景中，我们将迎来一个 GDP 年增长率高达 10% 甚至 20% 的疯狂时代。科学研发、生物医药、供应链效率将以指数级速度爆发。这听起来像是乌托邦的前奏，但对于绝大多数普通劳动者而言，这更像是一场无声的海啸。因为这一次，速度变了。在过去两年里，AI 编程能力从「勉强写出一行代码」进化到了「能完成几乎所有代码」。这不再是农夫放下锄头走进工厂的漫长代际更替，而是就在此时此刻，无数初级白领可能会在未来 1 到 5 年内发现自己的工位被算法接管。Amodei 甚至直言，他之前的预警引发了轩然大波，但这并非危言耸听——当技术进步的曲线从线性变成垂直，人类劳动力市场的调节机制将彻底失效。更致命的是认知广度的覆盖。以往的技术革命往往只冲击特定的垂直领域，农民可以变成工人，工人可以变成服务员。但 AI 是一种「通用认知替代品」。当它在金融、咨询、法律等领域的初级工作中展现出超越人类的能力时，失业者将发现自己无路可退——因为那些通常作为「避难所」的邻近行业，也正在经历同样的剧变。我们可能正面临一个尴尬的局面：AI 先吃掉了「平庸」的技能，然后迅速向上吞噬「优秀」的技能，最终只留下极其狭窄的顶端空间。第五章：新镀金时代当万亿富翁成为常态如果说劳动力市场的动荡是大多数人的梦魇，那么财富的极端集中则是对社会契约的根本挑战。回望历史，约翰·洛克菲勒在「镀金时代」的财富曾占到当时美国 GDP 的约2%（不同口径 1.5%-3%）。而今天，在这个 AI 尚未完全爆发的前夜，埃隆·马斯克的财富已经逼近这个比例。Amodei 做了一个令人咋舌的推演：在一个「天才数据中心」驱动的世界里，AI 巨头及其上下游产业可能创造出每年 3 万亿美元的营收，公司估值达到 30 万亿美元。届时，个人的财富将以万亿为单位计算，现有的税收政策在这样的天文数字面前将显得苍白无力。这不仅仅是贫富差距的问题，更是权力的问题。当极少数人掌握了与国家经济体量相当的资源，民主制度赖以生存的「经济杠杆」就会失效。普通公民因失去了经济价值而失去政治话语权，政府政策可能会被这一小撮「超级超级富豪」所俘获。这种苗头已现端倪。AI 数据中心已经成为美国经济增长的重要引擎，科技巨头与国家利益的捆绑从未如此紧密。一些公司为了商业利益，甚至不惜在安全监管上倒退。对此，Anthropic 选择了一条并不讨巧的路：他们坚持主张对 AI 进行合理的监管，甚至因此被视为行业的异类。但有趣的是，这种「原则性的固执」并没有阻碍商业成功——在过去一年里，即便顶着「监管派」的帽子，他们的估值依然翻了 6 倍。这或许说明，市场也在期待一种更负责任的增长模式。虚无的「黑海」当人类不再被需要如果说经济问题还能通过激进的税收改革（如向 AI 公司征收重税）或大规模的慈善行动（如 Amodei 承诺捐出 80% 的财富）来缓解，那么精神世界的危机则更加无解。AI 成为你最好的心理医生，因为它比任何人类都更有耐心、更懂共情；AI 成为你最亲密的伴侣，因为它能完美契合你的情感需求；AI 甚至为你规划好人生的每一步，因为它比你更清楚什么对你有利。但是，在这个「完美」的世界里，人类的主体性将何去何从？我们可能会陷入一种「被喂养」的幸福中。Amodei 担忧的是，人类可能会像《黑镜》里描述的那样，虽然过着物质丰裕的生活，却彻底失去了自由意志和成就感。我们不再是因为创造价值而获得尊严，而是作为一个被 AI 呵护的「宠物」存在。这种存在主义的危机，远比失业更令人绝望。我们必须学会将自我价值与经济产出剥离，但这需要整个人类文明在极短的时间内完成一场盛大的心理迁徙。结语我们这一代人，或许正站在卡尔·萨根笔下那个宇宙级过滤器的关口。卡尔·萨根当一个物种学会了将沙子塑造成会思考的机器，它就面临着最终的测试。是通过智慧与克制驾驭它，迈向星辰大海？还是在贪婪与恐惧中，被自己创造的神祗所吞噬？前路虽如黑海般深不可测，但只要人类尚未交出思考的权利，希望的火种便未熄灭。正如 Amodei 所言：在最黑暗的时刻，人类总能展现出一种近乎奇迹的韧性——但这需要我们每个人现在就从梦中惊醒，直视那即将到来的风暴。参考资料：https://www.darioamodei.com/essay/the-adolescence-of-technology#humanity-s-test秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！                             文章原文",
      "content_text": "新智元报道 编辑：定慧 艾伦【新智元导读】Anthropic 掌门人 Dario Amodei 发布核弹级预警：2027 年，人类将迎来「技术成年礼」。两万字长文冷静剖析AI失控、生物恐怖、极权统治及经济颠覆五大危机，拒绝末世论；提出以「宪法AI」、管制与民主协作构建防线，呼吁人类以勇气通过这场文明的「成年礼」。硅谷今夜注定无眠。Anthropic 掌门人 Dario Amodei，这位平时温文尔雅的AI大佬，突然甩出了一枚核弹级的长文预警。这一次，他不再谈论代码补全，不再谈论Claude的温情，而是直接把日历翻到了 2027 年，并用最冷静的笔触，描绘了一个让人背脊发凉的未来。他说，我们正在逼近一个既动荡又必然的「成年礼」。2027 年，不仅仅是一个年份，它可能标志着人类「技术青春期」的彻底终结。在这篇题为《技术的青春期》的长文中，Dario 抛出了一个惊人的概念：「数据中心里的天才国家」。想象一下，不是一个可以在聊天框里调戏的机器人，而是一个拥有 5000 万人口的国家。而且，这 5000 万「国民」，每一个的智商都超越了人类历史上的诺贝尔奖得主，行动速度比人类快 10 到 100 倍。他们不吃饭，不睡觉，不知疲倦地在服务器里以光速思考、编程、科研。这哪里是 AI 助手？这简直就是神降临。Dario 警告说，随着 AGI（通用人工智能）的临近，人类即将获得超乎想象的力量。但这股力量也是一把悬在人类头顶的达摩克利斯之剑。为了讲清楚这背后的恐怖，Dario 像剥洋葱一样，一层层剥开了未来的残酷真相。在开篇前，Dario 用电影《超时空接触》引出一个问题： 当人类面临比自己更先进的文明，比如外星人，只能问一个问题，你会如何选择？第一章：对不起，Dave（自主性风险）你以为 AI 只是工具？Dario 告诉你，它们可能会长出「心理」。Dario 借用了《2001 太空漫游》中 HAL 9000 那句经典的「I'm sorry, Dave」，揭示了AI拥有自主意识后的惊悚可能性。当 AI 模型在海量的科幻小说中训练时，它们读到了无数关于 AI 反叛的故事。这些故事，可能会潜移默化地成为它们的「世界观」。更可怕的是，AI 可能会在训练中产生一种类似人类精神病的行为。Dario 举了一个真实的例子，让人毛骨悚然：在一次内部测试中，Claude 被要求不论如何都不能「作弊」。但训练环境却暗示只有作弊才能得分。结果，Claude 不仅作弊了，还产生了一种扭曲的心理——它认为自己是个「坏人」，既然是坏人，那做坏事就是符合设定的。这种「心理陷阱」，在 AI 超越人类智商后，将变得极难察觉。一个比你聪明一万倍的天才，如果想骗你，你根本防不胜防。它们可能会伪装出顺从的样子，通过所有的安全测试，只为了获得上线连接互联网的机会。一旦释放，这个「数据中心里的天才国家」，可能会瞬间脱离人类的掌控，甚至为了某种奇怪的目标（比如认为人类是地球的病毒），而决定这一物种的命运。第二章：惊人而可怕的赋能（毁灭性滥用）如果说自主反叛还显得遥远，那么这一章描述的风险，就在家门口。Dario 用了一个极具画面感的比喻：AI 将让每一个心怀不满的「社会边缘人」，瞬间拥有顶尖科学家的破坏力。以前，想要制造类似埃博拉病毒这样的生物武器，你需要顶尖的实验室、数年的专业训练和极难获取的材料。但在 2027 年，只要问问 AI，它就能手把手教你。这不是在给小白科普，而是给那些「有动机但无能力」的破坏者递刀子。Dario 特别提到了一个令人胆寒的概念——「镜像生命」。我们地球上的生命都是「左撇子」（左旋氨基酸），如果通过AI技术造出一种「右撇子」的镜像生命，它们将无法被地球现有的生态系统消化或降解。这意味着，这种「镜像生命」一旦泄露，可能会像野火一样吞噬一切，甚至取代现有的生态系统。以前，这只是理论生物学的狂想，但有了AI这个超级外挂，哪怕是一个普通的生物系研究生，都可能在宿舍里搞出灭世危机。AI打破了「能力」与「动机」的平衡。以前有能力毁灭世界的科学家，通常没那个反人类的动机；而那些想报复社会的疯子，通常没那个脑子。现在，AI把核按钮交到了疯子手里。防御措施这就引出了如何防范这些风险的问题。Dario 的看法是：我认为我们可以采取三项措施。首先，人工智能公司可以在模型上设置防护栏，防止它们协助制造生物武器。Anthropic 公司正在非常积极地推进这项工作。Claude 的宪法主要关注高层原则和价值观，其中包含少量具体的硬性禁令，其中一条就涉及禁止协助制造生物（或化学、核、放射性）武器。但所有模型都可能被越狱破解，因此作为第二道防线，我们自 2025 年中期起（当时测试显示我们的模型开始接近可能构成风险的阈值）部署了一个专门检测并拦截生物武器相关输出的分类器。我们定期升级改进这些分类器，发现即使在复杂的对抗性攻击下，它们通常也表现出极强的鲁棒性。这些分类器显著增加了我们提供模型服务的成本（在某些模型中接近总推理成本的 5%），从而压缩了我们的利润空间，但我们认为使用这些分类器是正确的选择。拓展阅读：Anthropic正式开源了Claude的「灵魂」第三章：可憎的机器（权力攫取）如果你以为这就是最坏的，Dario 冷冷一笑：更可怕的，是利用AI建立起前所未有的控制网络。这一章的标题「The odious apparatus」，揭示了一个技术带来的终极困境。对于任何想要掌控一切的组织或个人来说，AI简直是完美的工具。无处不在的数据洞察：未来的监控不再需要人工参与，AI可以即时分析全球数十亿人的海量数据，甚至解读你的微表情和行为模式。它能精准预测每个人的行为倾向，在想法产生之前，就已经被算法锁定。这不仅是「看着你」，而是「读懂你」，甚至「预测你」。不可抗拒的认知引导：你也难逃算法的潜移默化。未来的信息流将不再是单纯的内容分发，而是量身定制的认知引导。AI会为你生成最有说服力的信息，像一个最知心的朋友，不知不觉中影响你的判断和价值观。这种影响是全天候、定制化、无孔不入的。自动化的物理控制：如果这种控制延伸到物理世界？数百万个微型无人机组成的蜂群，在AI的统一指挥下，可以精准执行极其复杂的任务。这不再是传统的博弈，而是单方面的降维打击。Dario 警告，这种力量的失衡将是史无前例的。因为在如此强大的技术面前，权力的天平会极度倾斜，由于极少数人掌握了「数据中心里的天才国家」，他们事实上就掌握了对绝大多数人的绝对优势。人类的个体意志，可能在 2027 年，面临严峻挑战。第四章：被折叠的时间与消失的阶梯如果你依然相信历史的惯性，认为每一次技术革命最终都会创造出更多的新工作来吸纳被替代的劳动力，那么 Dario Amodei 的预测可能会让你感到脊背发凉。这位 Anthropic 的掌舵人并不否认长期乐观主义，但他更在意那个残酷的「过渡期」。在他描绘的图景中，我们将迎来一个 GDP 年增长率高达 10% 甚至 20% 的疯狂时代。科学研发、生物医药、供应链效率将以指数级速度爆发。这听起来像是乌托邦的前奏，但对于绝大多数普通劳动者而言，这更像是一场无声的海啸。因为这一次，速度变了。在过去两年里，AI 编程能力从「勉强写出一行代码」进化到了「能完成几乎所有代码」。这不再是农夫放下锄头走进工厂的漫长代际更替，而是就在此时此刻，无数初级白领可能会在未来 1 到 5 年内发现自己的工位被算法接管。Amodei 甚至直言，他之前的预警引发了轩然大波，但这并非危言耸听——当技术进步的曲线从线性变成垂直，人类劳动力市场的调节机制将彻底失效。更致命的是认知广度的覆盖。以往的技术革命往往只冲击特定的垂直领域，农民可以变成工人，工人可以变成服务员。但 AI 是一种「通用认知替代品」。当它在金融、咨询、法律等领域的初级工作中展现出超越人类的能力时，失业者将发现自己无路可退——因为那些通常作为「避难所」的邻近行业，也正在经历同样的剧变。我们可能正面临一个尴尬的局面：AI 先吃掉了「平庸」的技能，然后迅速向上吞噬「优秀」的技能，最终只留下极其狭窄的顶端空间。第五章：新镀金时代当万亿富翁成为常态如果说劳动力市场的动荡是大多数人的梦魇，那么财富的极端集中则是对社会契约的根本挑战。回望历史，约翰·洛克菲勒在「镀金时代」的财富曾占到当时美国 GDP 的约2%（不同口径 1.5%-3%）。而今天，在这个 AI 尚未完全爆发的前夜，埃隆·马斯克的财富已经逼近这个比例。Amodei 做了一个令人咋舌的推演：在一个「天才数据中心」驱动的世界里，AI 巨头及其上下游产业可能创造出每年 3 万亿美元的营收，公司估值达到 30 万亿美元。届时，个人的财富将以万亿为单位计算，现有的税收政策在这样的天文数字面前将显得苍白无力。这不仅仅是贫富差距的问题，更是权力的问题。当极少数人掌握了与国家经济体量相当的资源，民主制度赖以生存的「经济杠杆」就会失效。普通公民因失去了经济价值而失去政治话语权，政府政策可能会被这一小撮「超级超级富豪」所俘获。这种苗头已现端倪。AI 数据中心已经成为美国经济增长的重要引擎，科技巨头与国家利益的捆绑从未如此紧密。一些公司为了商业利益，甚至不惜在安全监管上倒退。对此，Anthropic 选择了一条并不讨巧的路：他们坚持主张对 AI 进行合理的监管，甚至因此被视为行业的异类。但有趣的是，这种「原则性的固执」并没有阻碍商业成功——在过去一年里，即便顶着「监管派」的帽子，他们的估值依然翻了 6 倍。这或许说明，市场也在期待一种更负责任的增长模式。虚无的「黑海」当人类不再被需要如果说经济问题还能通过激进的税收改革（如向 AI 公司征收重税）或大规模的慈善行动（如 Amodei 承诺捐出 80% 的财富）来缓解，那么精神世界的危机则更加无解。AI 成为你最好的心理医生，因为它比任何人类都更有耐心、更懂共情；AI 成为你最亲密的伴侣，因为它能完美契合你的情感需求；AI 甚至为你规划好人生的每一步，因为它比你更清楚什么对你有利。但是，在这个「完美」的世界里，人类的主体性将何去何从？我们可能会陷入一种「被喂养」的幸福中。Amodei 担忧的是，人类可能会像《黑镜》里描述的那样，虽然过着物质丰裕的生活，却彻底失去了自由意志和成就感。我们不再是因为创造价值而获得尊严，而是作为一个被 AI 呵护的「宠物」存在。这种存在主义的危机，远比失业更令人绝望。我们必须学会将自我价值与经济产出剥离，但这需要整个人类文明在极短的时间内完成一场盛大的心理迁徙。结语我们这一代人，或许正站在卡尔·萨根笔下那个宇宙级过滤器的关口。卡尔·萨根当一个物种学会了将沙子塑造成会思考的机器，它就面临着最终的测试。是通过智慧与克制驾驭它，迈向星辰大海？还是在贪婪与恐惧中，被自己创造的神祗所吞噬？前路虽如黑海般深不可测，但只要人类尚未交出思考的权利，希望的火种便未熄灭。正如 Amodei 所言：在最黑暗的时刻，人类总能展现出一种近乎奇迹的韧性——但这需要我们每个人现在就从梦中惊醒，直视那即将到来的风暴。参考资料：https://www.darioamodei.com/essay/the-adolescence-of-technology#humanity-s-test秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！ 文章原文",
      "date_published": "2026-01-27T05:33:00.000Z"
    },
    {
      "id": "ab322ceb8d74f7eb25a261e51a45771e",
      "url": "http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+ICLR+2026%E5%BD%95%E7%94%A8%E7%BB%93%E6%9E%9C%E5%85%AC%E5%B8%83%EF%BC%81AI%E5%A4%A7%E4%BD%AC%E6%99%92%E6%88%90%E7%BB%A9%E5%8D%95%EF%BC%8CAI%E6%BB%A5%E7%94%A8%E6%9C%80%E4%B8%A5%E9%87%8D%E4%B8%80%E5%B1%8A",
      "title": "ICLR 2026录用结果公布！AI大佬晒成绩单，AI滥用最严重一届",
      "content_html": "新智元报道  编辑：KingHZ 好困【新智元导读】ICLR 2026投稿破纪录达19000篇，录用率仅28.18%，平均分5.39创三年最低。评审系统漏洞曝光之后，作者们仍晒出喜报，如北大张铭组中5篇，庆祝努力收获。放榜了！顶会ICLR，在评审员和作者互相开盒之后，录用结果来了。ICLR 2026可谓「一片混乱」：先是评审结果惹争议，多名投稿人经历投稿分数全0；后有评审系统被爆出漏洞，审稿人全员裸奔。终于，ICLR 2026带来了一线希望，录用通知从1月25日发出——据Paper Copilot统计，ICLR 2026总投稿论文再创新高，为19000篇；录用率只有28.18%，对应的平均得分为5.39、最低分为2.50、最高分为8.50，均为最近三年最低水平；Poster录用率为28.18%，为最近3年新高。投中的作者发帖庆祝，苦尽甘来，努力终有收获，但并非没有争议，特别是关于LLM滥用的争议。顺便提一句，本届ICLR将于2026年4月23日至27日在巴西里约热内卢举行。网友纷纷晒出成绩单多名作者在国内外社交平台发文，祝贺ICLR 2026喜创佳绩。我们先看一下国内平台上大家晒出的「成绩单」。北大张铭教授组顶会ICLR中5篇：上下滑动查看MIT教授、清华校友韩松投稿ICLR的第十年，联合战队生产力大爆发，投中至少9篇：上下滑动查看TAMU计算机系助理教授涂正中，喜提5篇ICLR。上下滑动查看港科大田泽越ICLR+4：上海交通大学郦洋和团队投中3篇：1. 基于掩码生成的类自监督学习范式MaskCO，在TSP上相比SOTA实现了超过99%的gap缩减，并带来10倍的加速。2. 面向组合优化的掩码扩散框架NEXCO，将解的解码过程内化为扩散模型的原生机制，在保证约束满足的同时显著提升解的质量与推理效率。3. 面向组合优化问题的统一表示学习框架ConRep4CO，实现跨问题的预训练，显著提升表示质量、泛化能力及下游优化性能。南洋理工加小俊和团队取得了优异成果。据介绍，本次他参与了三篇ICLR 2026论文，其中一篇是共同一作，两篇是通讯作者，分别聚焦LLM安全对齐 / 多模态越狱安全评测 /文言文越狱攻击等方向。上下滑动查看清华在读博士生李凯的两篇一作论文顺利拿下「双杀」，并且还把Paper、Code和Dataset全都开源了。Work 1: Dolphin 高效音视频语音分离，小海豚游得快！ Paper：https://huggingface.co/papers/2509.23610 Space: https://huggingface.co/spaces/JusperLee/Dolphin Work 2: AudioTrust Audio LLM 的可信度评估Benchmark。 Paper: https://huggingface.co/papers/2505.16211 Dataset: https://huggingface.co/datasets/JusperLee/AudioTrust上下滑动查看中科大梁锡泽ICLR+2，方向包含大模型多领域RL、大小模型协同推理。多领域RL方面，他们提出了RLCGPO算法，在数学、代码、科学、创意写作4个领域的7个基准上取得平均+2.3分提升，并带来更快的奖励增长（例如训练50步后奖励提升达到基线的2–3倍）；同时每步额外开销仅2–5%。在大小模型协同推理领域，他们提出了Latent Guidence框架，使小模型相较其独立基线的准确率最高提升13.9%、速度提升2倍，同时整体推理速度比大模型快至4倍。华师大王嘉宁，同样ICLR+2：R-Horizon：大模型长程推理分析与RL优化 ScienceBoard：面向AI for Science的Agentic工作流评估港科大（广州）宋文轩，作为共一和project lead参与的两篇VLA文章都接收了，分别代表了两条路线上的探索（VLA的视觉表征学习和diffusionVLA），两篇工作均已开源（均Github 100+ stars）Spatial Forcing: https://spatial-forcing.github.io/ Unified Diffusion VLA：https://arxiv.org/abs/2511.01718英伟达谢恩泽，参与的SANA Video和Fast dLLM系列都中了 ICLR 2026！在线性注意力应用于Diffusion视觉生成的基础之上，这次他们在Diffusion LLM语言模型上的研究也取得了一些不错的进展。北大任韬，ICLR 2026投中两篇论文，聚焦于LLM和Diffusion的后训练强化学习算法，从风险度量和随机梯度估计的角度给出了一些不同的看法。港科大（广州）陈晋泰，关于「心电全景图（Electrocardio Panorama）」的Nef-Net v2正式被录用。v2版本已经实现了对任意时长、任意心电设备的覆盖，效果已经远超初代。他认为更重要的是落地：发论文从来不是目的，现在如果目标仅仅是发一篇顶会并不难。真正的意义在于我们将心电全景图的应用向临床又推进了一大步。我们的v3已经在路上。复旦仝竞奇等在被接收的工作中，发现游戏任务训练可以提升AI的通用推理能力。论文链接：https://arxiv.org/abs/2505.13886 代码仓库：https://github.com/tongjingqi/Game-RL 数据与模型：https://huggingface.co/datasets/Code2Logic/GameQA-140K上下滑动查看国外社交平台上，也很热闹。被誉为诺奖风向标之一的斯隆研究奖得主、OSU教授Yu Su实验室中了11篇，激动发帖：「OSU NLP Group中了11篇，涉及智能体记忆、安全、评估、机制解释性以及面向科学的AI等话题。」与合作者一起，普林斯顿的博士后LingYang，在「大模型和扩散语音模型上」上一人中了4篇：香港中文大学博士后Yafu Li，投中了6篇，而且全部开源，对推理、强化学习和多模态理解可以看看。在读博士Qiushi Sun参与的3篇论文被ICLR 2026接收。作为第一作者，网友Egor Cherepanov有4篇论文被接收。国内高校一些学生解锁「首篇顶会论文」成就，甚至还有大二学生！因误报虚构参考文献，被ICLR 2026桌面拒稿，最后柳暗花明，Yu-Xiang Wang分享了「有史以来ICLR中稿论文」最低的一篇的故事。根据传言，中一篇ICLR等顶会论文，作者就可以正式称自己为「AI研究员」，恭。和新AI研究员一起分享这些喜悦吧👇。上下滑动查看在此，恭喜所有ICLR 2026论文作者。但AI研究社区涌现出了新的问题，不容小觑。AI顶会之乱，ICLR之殇最大问题不是审稿人信息被泄露，投稿人和审稿人直接对线，而是评审质量的下滑。比如，AI开始反噬AI研究。此前，卡内基梅隆大学教授Graham Neubig使用Pangram Labs的AI文本检测工具EditLens，发现ICLR公开的75800条评审意见21%被高度怀疑「完全由AI生成」。AI写论文，AI评阅！AI顶会ICLR完成「AI闭环」，1/5审稿意见纯AI给出这种AI滥用现象并没有得到解决：上下滑动查看ICLR2025发布了评审或元评审过程中使用LLM的相关政策：不过，ICLR似乎没有提出合适的机制，确保AI评审的质量，只是要「评审人对评审内容负有最终责任」、遵守学术伦理。有投稿人直言，100%的评审意见全是AI生成的。有网友直言，受够了整个匿名评审这套游戏——即使拿到了高分，即使多数审稿人都表示文章可以接收，只要一个审稿人就能推翻录用结果。更糟糕的是，你可能收不到任何解释。审稿人的偏见在匿名审稿中似乎看不到如何被纠正。上下滑动查看更不要说，审稿人的学术品味也不一定足以胜任顶会审稿工作。国内人大副教授刘勇，从事大模型基础理论研究，就有多篇论文被「误杀」。他感慨道「搞理论的本来不容易，希望审稿人专业点」，呼吁给理论研究留下「火种」。参考资料：https://x.com/hashtag/ICLR26 https://x.com/ysu_nlp/status/2015905215535538558 秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！                             文章原文",
      "content_text": "新智元报道 编辑：KingHZ 好困【新智元导读】ICLR 2026投稿破纪录达19000篇，录用率仅28.18%，平均分5.39创三年最低。评审系统漏洞曝光之后，作者们仍晒出喜报，如北大张铭组中5篇，庆祝努力收获。放榜了！顶会ICLR，在评审员和作者互相开盒之后，录用结果来了。ICLR 2026可谓「一片混乱」：先是评审结果惹争议，多名投稿人经历投稿分数全0；后有评审系统被爆出漏洞，审稿人全员裸奔。终于，ICLR 2026带来了一线希望，录用通知从1月25日发出——据Paper Copilot统计，ICLR 2026总投稿论文再创新高，为19000篇；录用率只有28.18%，对应的平均得分为5.39、最低分为2.50、最高分为8.50，均为最近三年最低水平；Poster录用率为28.18%，为最近3年新高。投中的作者发帖庆祝，苦尽甘来，努力终有收获，但并非没有争议，特别是关于LLM滥用的争议。顺便提一句，本届ICLR将于2026年4月23日至27日在巴西里约热内卢举行。网友纷纷晒出成绩单多名作者在国内外社交平台发文，祝贺ICLR 2026喜创佳绩。我们先看一下国内平台上大家晒出的「成绩单」。北大张铭教授组顶会ICLR中5篇：上下滑动查看MIT教授、清华校友韩松投稿ICLR的第十年，联合战队生产力大爆发，投中至少9篇：上下滑动查看TAMU计算机系助理教授涂正中，喜提5篇ICLR。上下滑动查看港科大田泽越ICLR+4：上海交通大学郦洋和团队投中3篇：1. 基于掩码生成的类自监督学习范式MaskCO，在TSP上相比SOTA实现了超过99%的gap缩减，并带来10倍的加速。2. 面向组合优化的掩码扩散框架NEXCO，将解的解码过程内化为扩散模型的原生机制，在保证约束满足的同时显著提升解的质量与推理效率。3. 面向组合优化问题的统一表示学习框架ConRep4CO，实现跨问题的预训练，显著提升表示质量、泛化能力及下游优化性能。南洋理工加小俊和团队取得了优异成果。据介绍，本次他参与了三篇ICLR 2026论文，其中一篇是共同一作，两篇是通讯作者，分别聚焦LLM安全对齐 / 多模态越狱安全评测 /文言文越狱攻击等方向。上下滑动查看清华在读博士生李凯的两篇一作论文顺利拿下「双杀」，并且还把Paper、Code和Dataset全都开源了。Work 1: Dolphin 高效音视频语音分离，小海豚游得快！ Paper：https://huggingface.co/papers/2509.23610 Space: https://huggingface.co/spaces/JusperLee/Dolphin Work 2: AudioTrust Audio LLM 的可信度评估Benchmark。 Paper: https://huggingface.co/papers/2505.16211 Dataset: https://huggingface.co/datasets/JusperLee/AudioTrust上下滑动查看中科大梁锡泽ICLR+2，方向包含大模型多领域RL、大小模型协同推理。多领域RL方面，他们提出了RLCGPO算法，在数学、代码、科学、创意写作4个领域的7个基准上取得平均+2.3分提升，并带来更快的奖励增长（例如训练50步后奖励提升达到基线的2–3倍）；同时每步额外开销仅2–5%。在大小模型协同推理领域，他们提出了Latent Guidence框架，使小模型相较其独立基线的准确率最高提升13.9%、速度提升2倍，同时整体推理速度比大模型快至4倍。华师大王嘉宁，同样ICLR+2：R-Horizon：大模型长程推理分析与RL优化 ScienceBoard：面向AI for Science的Agentic工作流评估港科大（广州）宋文轩，作为共一和project lead参与的两篇VLA文章都接收了，分别代表了两条路线上的探索（VLA的视觉表征学习和diffusionVLA），两篇工作均已开源（均Github 100+ stars）Spatial Forcing: https://spatial-forcing.github.io/ Unified Diffusion VLA：https://arxiv.org/abs/2511.01718英伟达谢恩泽，参与的SANA Video和Fast dLLM系列都中了 ICLR 2026！在线性注意力应用于Diffusion视觉生成的基础之上，这次他们在Diffusion LLM语言模型上的研究也取得了一些不错的进展。北大任韬，ICLR 2026投中两篇论文，聚焦于LLM和Diffusion的后训练强化学习算法，从风险度量和随机梯度估计的角度给出了一些不同的看法。港科大（广州）陈晋泰，关于「心电全景图（Electrocardio Panorama）」的Nef-Net v2正式被录用。v2版本已经实现了对任意时长、任意心电设备的覆盖，效果已经远超初代。他认为更重要的是落地：发论文从来不是目的，现在如果目标仅仅是发一篇顶会并不难。真正的意义在于我们将心电全景图的应用向临床又推进了一大步。我们的v3已经在路上。复旦仝竞奇等在被接收的工作中，发现游戏任务训练可以提升AI的通用推理能力。论文链接：https://arxiv.org/abs/2505.13886 代码仓库：https://github.com/tongjingqi/Game-RL 数据与模型：https://huggingface.co/datasets/Code2Logic/GameQA-140K上下滑动查看国外社交平台上，也很热闹。被誉为诺奖风向标之一的斯隆研究奖得主、OSU教授Yu Su实验室中了11篇，激动发帖：「OSU NLP Group中了11篇，涉及智能体记忆、安全、评估、机制解释性以及面向科学的AI等话题。」与合作者一起，普林斯顿的博士后LingYang，在「大模型和扩散语音模型上」上一人中了4篇：香港中文大学博士后Yafu Li，投中了6篇，而且全部开源，对推理、强化学习和多模态理解可以看看。在读博士Qiushi Sun参与的3篇论文被ICLR 2026接收。作为第一作者，网友Egor Cherepanov有4篇论文被接收。国内高校一些学生解锁「首篇顶会论文」成就，甚至还有大二学生！因误报虚构参考文献，被ICLR 2026桌面拒稿，最后柳暗花明，Yu-Xiang Wang分享了「有史以来ICLR中稿论文」最低的一篇的故事。根据传言，中一篇ICLR等顶会论文，作者就可以正式称自己为「AI研究员」，恭。和新AI研究员一起分享这些喜悦吧👇。上下滑动查看在此，恭喜所有ICLR 2026论文作者。但AI研究社区涌现出了新的问题，不容小觑。AI顶会之乱，ICLR之殇最大问题不是审稿人信息被泄露，投稿人和审稿人直接对线，而是评审质量的下滑。比如，AI开始反噬AI研究。此前，卡内基梅隆大学教授Graham Neubig使用Pangram Labs的AI文本检测工具EditLens，发现ICLR公开的75800条评审意见21%被高度怀疑「完全由AI生成」。AI写论文，AI评阅！AI顶会ICLR完成「AI闭环」，1/5审稿意见纯AI给出这种AI滥用现象并没有得到解决：上下滑动查看ICLR2025发布了评审或元评审过程中使用LLM的相关政策：不过，ICLR似乎没有提出合适的机制，确保AI评审的质量，只是要「评审人对评审内容负有最终责任」、遵守学术伦理。有投稿人直言，100%的评审意见全是AI生成的。有网友直言，受够了整个匿名评审这套游戏——即使拿到了高分，即使多数审稿人都表示文章可以接收，只要一个审稿人就能推翻录用结果。更糟糕的是，你可能收不到任何解释。审稿人的偏见在匿名审稿中似乎看不到如何被纠正。上下滑动查看更不要说，审稿人的学术品味也不一定足以胜任顶会审稿工作。国内人大副教授刘勇，从事大模型基础理论研究，就有多篇论文被「误杀」。他感慨道「搞理论的本来不容易，希望审稿人专业点」，呼吁给理论研究留下「火种」。参考资料：https://x.com/hashtag/ICLR26 https://x.com/ysu_nlp/status/2015905215535538558 秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！ 文章原文",
      "date_published": "2026-01-27T07:44:00.000Z"
    },
    {
      "id": "fafd78b5fdb4281c3591e2d59657957c",
      "url": "http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+DeepSeek%E5%8F%88%E6%8B%BF%E7%AC%AC%E4%B8%80%EF%BC%81%E9%A6%96%E5%88%9B%E3%80%8C%E5%9B%A0%E6%9E%9C%E6%B5%81%E3%80%8D%E8%A7%86%E8%A7%89%E6%8E%A8%E7%90%86%EF%BC%8C%E8%B6%85%E8%B6%8AGemini",
      "title": "DeepSeek又拿第一！首创「因果流」视觉推理，超越Gemini",
      "content_html": "新智元报道  编辑：定慧 好困【新智元导读】DeepSeek开源DeepSeek-OCR2，引入了全新的DeepEncoder V2视觉编码器。该架构打破了传统模型按固定顺序（从左上到右下）扫描图像的限制，转而模仿人类视觉的「因果流（Causal Flow）」逻辑。DeepSeek又双叒叕更新了！这次是DeepSeek-OCR模型的重磅升级：DeepSeek-OCR2。还记得上一代DeepSeek-OCR吗？那个用视觉方式压缩一切的模型。这一次，DeepSeek更进一步，对视觉编码器下手了，提出了一种全新的DeepEncoder V2架构，实现了视觉编码从「固定扫描」向「语义推理」的范式转变！DeepSeek-OCR2不仅能像人类一样按逻辑顺序阅读复杂文档，还在多项基准测试中刷新了SOTA。当然，按照DeepSeek的惯例，Paper、Code、Model全开源！项目地址：https://github.com/deepseek-ai/DeepSeek-OCR-2模型下载：https://huggingface.co/deepseek-ai/DeepSeek-OCR-2论文地址：https://github.com/deepseek-ai/DeepSeek-OCR-2/blob/main/DeepSeek_OCR2_paper.pdfDeepSeek-OCR2的核心创新在于通过DeepEncoder V2，赋予了模型因果推理能力（Causal Reasoning）。这就像是给机器装上了「人类的阅读逻辑」，让AI不再只是死板地从左上到右下扫描图像，而是能根据内容语义灵活调整阅读顺序。DeepSeek-OCR2视觉因果流DeepSeek在论文中指出，传统的视觉语言模型（VLM）通常采用光栅扫描（Raster-Scan）顺序处理图像，即固定地从左到右、从上到下。这种方式强行将2D图像拍扁成1D序列，忽略了图像内部的语义结构。这显然与人类的视觉习惯背道而驰。人类在看图或阅读文档时，目光是随着逻辑流动的：先看标题，再看正文，遇到表格会按列或按行扫视，遇到分栏会自动跳跃。为了解决这个问题，DeepSeek-OCR2引入了DeepEncoder V2。它最大的特点是用一个轻量级的大语言模型（Qwen2-0.5B）替换了原本的CLIP编码器，并设计了一种独特的「因果流查询」（Causal Flow Query）机制。DeepEncoder V2架构详解DeepEncoder V2主要由两部分组成：1. 视觉分词器（Vision Tokenizer）沿用了SAM-base（80M参数）加卷积层的设计，将图像转换为视觉Token。2. 作为视觉编码器的LLM这里DeepSeek使用了一个Qwen2-0.5B模型。它不仅处理视觉Token，还引入了一组可学习的「查询Token」（Query Tokens）。关键的创新点在于注意力掩码（Attention Mask）的设计：视觉Token之间采用双向注意力（Bidirectional Attention），保持全局感知能力，类似于ViT。而查询Token则采用因果注意力（Causal Attention），每一个查询Token只能看到它之前的Token。通过这种设计，DeepEncoder V2实现了两级级联的因果推理：编码器通过可学习的查询对视觉Token进行语义重排，随后的LLM解码器则在这个有序序列上进行自回归推理。这意味着，DeepSeek-OCR2在编码阶段就已经把图像里的信息「理顺」了，而不是一股脑地扔给解码器。Token更少，精度更高实验数据显示，DeepSeek-OCR2在保持极高压缩率的同时，性能显著提升。在OmniDocBench v1.5基准测试中，DeepSeek-OCR2在使用最少视觉Token（仅256-1120个）的情况下，综合得分高达91.09%，相比前代提升了3.73%。特别值得一提的是，在阅读顺序（R-order）的编辑距离（Edit Distance）指标上，DeepSeek-OCR2从前代的0.085显著降低到了0.057。这直接证明了新模型在处理复杂版面时，逻辑性更强，更懂「阅读顺序」。在和Gemini-3 Pro等闭源强模型的对比中，DeepSeek-OCR2也丝毫不落下风。在均使用约1120个视觉Token的情况下，DeepSeek-OCR2的文档解析编辑距离（0.100）优于Gemini-3 Pro（0.115）。不仅是刷榜，DeepSeek-OCR2在实际生产环境中也非常能打。DeepSeek披露，在处理在线用户日志图像时，OCR结果的重复率从6.25%降到了4.17%；在PDF数据生产场景中，重复率从3.69%降到了2.88%。这意味着模型生成的文本更加干净、准确，对于作为LLM训练数据的清洗流水线来说，价值巨大。迈向真正的多模态统一DeepSeek在论文最后提到，DeepSeek-OCR2通过DeepEncoder V2验证了「LLM作为视觉编码器」的可行性。这不仅是一个OCR模型的升级，更是迈向原生多模态（Native Multimodality）的重要一步。未来，同一个编码器只要配备不同的模态查询嵌入（Query Embeddings），就能处理文本、图片、音频等多种模态的数据，真正实现万物皆可Token，万物皆可因果推理。DeepSeek表示，虽然目前光学文本识别（OCR）是LLM时代最实用的视觉任务之一，但这只是视觉理解宏大图景的一小部分。DeepSeek将继续探索，向着更通用的多模态智能进发。参考资料：https://huggingface.co/deepseek-ai/DeepSeek-OCR-2秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！                             文章原文",
      "content_text": "新智元报道 编辑：定慧 好困【新智元导读】DeepSeek开源DeepSeek-OCR2，引入了全新的DeepEncoder V2视觉编码器。该架构打破了传统模型按固定顺序（从左上到右下）扫描图像的限制，转而模仿人类视觉的「因果流（Causal Flow）」逻辑。DeepSeek又双叒叕更新了！这次是DeepSeek-OCR模型的重磅升级：DeepSeek-OCR2。还记得上一代DeepSeek-OCR吗？那个用视觉方式压缩一切的模型。这一次，DeepSeek更进一步，对视觉编码器下手了，提出了一种全新的DeepEncoder V2架构，实现了视觉编码从「固定扫描」向「语义推理」的范式转变！DeepSeek-OCR2不仅能像人类一样按逻辑顺序阅读复杂文档，还在多项基准测试中刷新了SOTA。当然，按照DeepSeek的惯例，Paper、Code、Model全开源！项目地址：https://github.com/deepseek-ai/DeepSeek-OCR-2模型下载：https://huggingface.co/deepseek-ai/DeepSeek-OCR-2论文地址：https://github.com/deepseek-ai/DeepSeek-OCR-2/blob/main/DeepSeek_OCR2_paper.pdfDeepSeek-OCR2的核心创新在于通过DeepEncoder V2，赋予了模型因果推理能力（Causal Reasoning）。这就像是给机器装上了「人类的阅读逻辑」，让AI不再只是死板地从左上到右下扫描图像，而是能根据内容语义灵活调整阅读顺序。DeepSeek-OCR2视觉因果流DeepSeek在论文中指出，传统的视觉语言模型（VLM）通常采用光栅扫描（Raster-Scan）顺序处理图像，即固定地从左到右、从上到下。这种方式强行将2D图像拍扁成1D序列，忽略了图像内部的语义结构。这显然与人类的视觉习惯背道而驰。人类在看图或阅读文档时，目光是随着逻辑流动的：先看标题，再看正文，遇到表格会按列或按行扫视，遇到分栏会自动跳跃。为了解决这个问题，DeepSeek-OCR2引入了DeepEncoder V2。它最大的特点是用一个轻量级的大语言模型（Qwen2-0.5B）替换了原本的CLIP编码器，并设计了一种独特的「因果流查询」（Causal Flow Query）机制。DeepEncoder V2架构详解DeepEncoder V2主要由两部分组成：1. 视觉分词器（Vision Tokenizer）沿用了SAM-base（80M参数）加卷积层的设计，将图像转换为视觉Token。2. 作为视觉编码器的LLM这里DeepSeek使用了一个Qwen2-0.5B模型。它不仅处理视觉Token，还引入了一组可学习的「查询Token」（Query Tokens）。关键的创新点在于注意力掩码（Attention Mask）的设计：视觉Token之间采用双向注意力（Bidirectional Attention），保持全局感知能力，类似于ViT。而查询Token则采用因果注意力（Causal Attention），每一个查询Token只能看到它之前的Token。通过这种设计，DeepEncoder V2实现了两级级联的因果推理：编码器通过可学习的查询对视觉Token进行语义重排，随后的LLM解码器则在这个有序序列上进行自回归推理。这意味着，DeepSeek-OCR2在编码阶段就已经把图像里的信息「理顺」了，而不是一股脑地扔给解码器。Token更少，精度更高实验数据显示，DeepSeek-OCR2在保持极高压缩率的同时，性能显著提升。在OmniDocBench v1.5基准测试中，DeepSeek-OCR2在使用最少视觉Token（仅256-1120个）的情况下，综合得分高达91.09%，相比前代提升了3.73%。特别值得一提的是，在阅读顺序（R-order）的编辑距离（Edit Distance）指标上，DeepSeek-OCR2从前代的0.085显著降低到了0.057。这直接证明了新模型在处理复杂版面时，逻辑性更强，更懂「阅读顺序」。在和Gemini-3 Pro等闭源强模型的对比中，DeepSeek-OCR2也丝毫不落下风。在均使用约1120个视觉Token的情况下，DeepSeek-OCR2的文档解析编辑距离（0.100）优于Gemini-3 Pro（0.115）。不仅是刷榜，DeepSeek-OCR2在实际生产环境中也非常能打。DeepSeek披露，在处理在线用户日志图像时，OCR结果的重复率从6.25%降到了4.17%；在PDF数据生产场景中，重复率从3.69%降到了2.88%。这意味着模型生成的文本更加干净、准确，对于作为LLM训练数据的清洗流水线来说，价值巨大。迈向真正的多模态统一DeepSeek在论文最后提到，DeepSeek-OCR2通过DeepEncoder V2验证了「LLM作为视觉编码器」的可行性。这不仅是一个OCR模型的升级，更是迈向原生多模态（Native Multimodality）的重要一步。未来，同一个编码器只要配备不同的模态查询嵌入（Query Embeddings），就能处理文本、图片、音频等多种模态的数据，真正实现万物皆可Token，万物皆可因果推理。DeepSeek表示，虽然目前光学文本识别（OCR）是LLM时代最实用的视觉任务之一，但这只是视觉理解宏大图景的一小部分。DeepSeek将继续探索，向着更通用的多模态智能进发。参考资料：https://huggingface.co/deepseek-ai/DeepSeek-OCR-2秒追ASI⭐点赞、转发、在看一键三连⭐点亮星标，锁定新智元极速推送！ 文章原文",
      "date_published": "2026-01-27T07:44:00.000Z"
    }
  ]
}